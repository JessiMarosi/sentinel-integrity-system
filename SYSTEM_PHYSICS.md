# Sentinel Integrity System (SIS)
## SYSTEM_PHYSICS.md

This document defines the **system physics** SIS is built upon.

SIS is not a moral system.
SIS is not a governance system.
SIS is not an intelligence system.

SIS is a **pre-harm physics system**: it surfaces when a system is approaching a state that cannot be easily reversed, regardless of intent, correctness, or outcome.

---

## 1. Why System Physics

Most integrity failures are not caused by bad actors.
They are caused by **structural properties** that make reversal infeasible once a threshold is crossed.

These properties behave like physics:

- they apply regardless of intent
- they compound silently
- they are indifferent to policy
- they cannot be negotiated with after the fact

SIS exists to surface those properties **before** they dominate.

---

## 2. The Pre-Harm Epistemic Zone

SIS operates in what we define as the **Pre-Harm Epistemic Zone**.

This zone exists:

- before evidence exists
- before policy applies cleanly
- before violations can be asserted
- before attribution is possible
- before outcomes are known

In this zone:
- decisions may still be technically correct
- no rule may yet be violated
- rollback may still be cheap
- harm may not be provable

This is precisely why the zone is ignored.

SIS is designed to operate *only* here.

---

## 3. Trajectory vs. State

Most systems reason about **state**:
- current configuration
- current permissions
- current compliance
- current metrics

SIS reasons about **trajectory**:
- direction of change
- convergence of properties
- rate at which reversibility is decaying

A system can be safe in its current state while moving rapidly toward an irreversible condition.

SIS exists to surface that motion.

---

## 4. The Three Axes of Irreversibility

SIS models irreversibility as the **convergence of three independent axes**.

No single axis is sufficient.
No axis is evaluated in isolation.
Only convergence matters.

---

### 4.1 Irreversibility

Irreversibility describes **how difficult it would be to undo a decision once executed**.

This includes, but is not limited to:

- rollback cost increasing faster than deployment speed
- dependency entanglement
- irreversible data propagation
- loss of clean restore points
- contractual or legal lock-in
- human or organizational dependency formation

Irreversibility is temporal.
It increases over time even when systems appear stable.

---

### 4.2 Opacity

Opacity describes **how difficult it is for humans to reason about the systems behavior**.

Opacity increases when:

- automation outpaces explainability
- decision logic is distributed across layers
- responsibility is fragmented
- emergent behavior replaces designed behavior
- no single actor can explain the full system

Opacity does not imply malice or incompetence.
It is a natural consequence of scale and speed.

---

### 4.3 Asymmetry

Asymmetry describes **how unevenly consequences are distributed**.

Asymmetry exists when:

- benefits are localized but harms are global
- decision-makers are insulated from impact
- recovery costs are borne by parties without authority
- failure cascades cross organizational or jurisdictional boundaries

Asymmetry amplifies harm even when probability is low.

---

## 5. Convergence, Not Measurement

SIS does **not** score these axes.
SIS does **not** assign weights.
SIS does **not** calculate probabilities.

SIS observes **directional convergence**.

An advisory may only be justified when:

- irreversibility is increasing
- opacity is increasing
- asymmetry is increasing

If any axis is absent, SIS remains silent.

Silence is a feature, not a failure.

---

## 6. Why SIS Does Not Act

Physics does not enforce behavior.
It reveals constraints.

SIS introduces **friction**, not force.

The moment SIS blocks, approves, or mandates action, it ceases to describe physics and begins to exercise authority.

Authority invalidates SIS.

---

## 7. Temporal Sensitivity

SIS is temporally sensitive, not outcome sensitive.

SIS cares **when** a condition is emerging, not **what** the condition will become.

Once harm is provable:
- SIS is already too late
- governance systems take over
- SIS must remain silent

SIS is not a post-mortem system.

---

## 8. Ephemerality as a Physical Property

In SIS, ephemerality is not a storage choice.
It is a **security property**.

Persistence creates:
- leverage
- attribution
- power
- retroactive interpretation

Retroactive interpretation collapses the pre-harm zone.

Therefore:
- advisories expire
- artifacts do not aggregate
- meaning remains local
- history does not accumulate

This preserves SISs ability to operate before blame exists.

---

## 9. Observer Effects and Self-Limitation

SIS acknowledges observer effects.

If SIS output becomes:

- enforceable
- auditable
- centralizable
- optimizable

Then SIS changes the system it observes.

To avoid this, SIS deliberately limits itself.

Self-limitation is not weakness.
It is structural integrity.

---

## 10. Failure as a Valid Outcome

SIS may surface risk and still be ignored.
Harm may still occur.
Decisions may still be irreversible.

This does not invalidate SIS.

SISs success condition is narrower:

That irreversible trajectories were visible **before** they became undeniable.

Visibility without control is the point.

---

## Closing Statement

SIS does not exist to stop failure.
It exists to make **silent irreversibility impossible**.

The physics SIS surfaces are already present.
SIS merely refuses to let them remain invisible.

If this document reads like restraint rather than capability, it is correct.

SIS is built on the belief that the most dangerous systems are not those that act badly,
but those that cross irreversible thresholds quietly.
